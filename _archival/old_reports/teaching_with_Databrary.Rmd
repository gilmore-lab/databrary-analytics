---
title: "Databrary-and-teaching"
author: "Rick O. Gilmore"
date: "`r Sys.time()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Purpose

To generate data for a talk Karen will be giving at the [National Institute on the Teaching of Psychology (NITOP)](https://nitop.org/).

## Set-up

```
login_db("email@address.com") # substitute proper account name
```

## Stats on shared videos, sessions, and video hrs

The `get_video_stats()` function should do this.

```{r}
get_video_stats(vol.id = 1)
```

However, this function is *very* slow on big volumes like <https://nyu.databrary.org/volume/8>.
The function `get_video_stats()` calls `list_assets_by_type()` with the default `type="video"` parameter.

Clearly, we need to optimize these routines and make them more efficient.
For now, I think I will write the output to a CSV file then remerge these.

```{r}
vols <- 1:5

write_vid_csv <- function(vol.id = 1) {
  message(paste0("Getting data for volume ", vol.id))
  vid_dat <- get_video_stats(vol.id)
  # This .Rmd file is already in working/
  if (!is.null(vid_dat)) {
    write.csv(vid_dat, file = paste0("csv/vol_", vol.id, ".csv"),
              row.names = FALSE)
  }
}  
lapply(vols, write_vid_csv)
```

Ok, that seems to work. Let's set it to work and go do something else for a bit.

```{r}
nine_to_20 <- 9:20
lapply(nine_to_20, write_vid_csv)
```

```{r}
next_vols <- 21:50
lapply(next_vols, write_vid_csv)
```

```{r}
lapply(51:100, write_vid_csv)
```

By the way, it would be good to be able to query the maximum volume ID. I think it is 763 today 2018-12-27-16:24.

```{r}
lapply(101:150, write_vid_csv)
```

```{r}
lapply(151:200, write_vid_csv)
```

```{r}
lapply(201:250, write_vid_csv)
```

```{r}
lapply(251:300, write_vid_csv)
```

```{r}
lapply(301:351, write_vid_csv)
```

```{r}
lapply(351:400, write_vid_csv)
```

```{r}
lapply(401:451, write_vid_csv)
```

```{r}
lapply(451:500, write_vid_csv)
```

```{r}
lapply(501:551, write_vid_csv)
```

```{r}
lapply(551:600, write_vid_csv)
```

```{r}
lapply(601:651, write_vid_csv)
```

```{r}
lapply(651:700, write_vid_csv)
```

```{r}
lapply(701:763, write_vid_csv)
```

Now that we have the CSV files, we can merge them into a single data file.

```{r}
csv_files <- list.files(path = "csv", pattern = "\\.csv$", full.names = TRUE)
```

So, I have access to `r length(csv_files)`.

```{r}
# Import the individual csv files
video_data <- lapply(list.files("csv", pattern="\\.csv$",
                                full.names = TRUE), read.csv, 
                     header = TRUE, sep = ",")

video_stats <- Reduce(function(x,y) merge(x, y, all = TRUE), video_data)
```

The median number of videos per volume is `r median(video_stats$n_videos)` with a range of [`r min(video_stats$n_videos)`, `r max(video_stats$n_videos)`].

But let's get more metadata about the volumes so we can give a fuller report.

```{r}
vols <- video_stats$vol_id
vol_info <- lapply(vols, list_volume_metadata)
vols_data <- Reduce(function(x,y) merge(x, y, all = TRUE), vol_info)
vols_joined <- dplyr::left_join(vols_data, video_stats, by = c("vol.id" = "vol_id"))
```

NB:

Permission 2: Access via Databrary sharing only
Permission 3: Non-named collaborator (through X?)
Permission 4: Named collaborator
Permission 5: Investigator, Volume overview shared OR Private

I need to dig in to determine what variable depicts the sharing level.

For now, let's note that volumes with permission == 2 are available to all Databrary users.
Volumes with a DOI have partial information available to all Databrary users.
So, there are `r dim(vols_data[vols_data$doi != "NA",])[1]` volumes with DOIs that have sessions and at least one video.
As of today (2018-12-28-09:52) that is 115.

Let's export a CSV of these.

```{r}
shared_vols_w_video <- vols_joined %>% 
  dplyr::filter(doi != "NA")

write.csv(shared_vols_w_video, file = "shared_vols_w_video_2018-12-28.csv", row.names = FALSE)
```

