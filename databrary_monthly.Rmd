---
title: "Databrary Monthly"
author: "Rick O. Gilmore"
date: "`r Sys.time()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    code_folding: hide
    self_contained: false
params:
  db_account: rogilmore@psu.edu
  #db_account: andrea.seisler@databrary.org
  vols_to_test: 10
  update_gs: false
  update_stats: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)

library(databraryapi)
library(tidyverse)
library(reshape2)
library(cowplot)
library(plyr)
library(googledrive)
  drive_auth(use_oob = TRUE)
library(googlesheets) 
  options(httr_oob_default=TRUE) 

if (!databraryapi::login_db(params$db_account)) {
  message("Log-in failed.")
}

# Graphic theme elements
ln_size <- 3
base_size <- 14
color_orange <- "#ec7751"
color_teal <- "#4CAE99"
color_purple <-"#AB00FF"

databrary_theme <- 
  theme_classic(base_size = base_size) +
  theme(axis.title.x=element_blank()) +
  theme(legend.position="none", 
        axis.text = element_text(size = rel(0.8), colour = "black")) +
  theme(axis.line = element_blank())
```

# Institutions & Authorized Users

At the moment, the `old_stats` come from a CSV stored locally.
Once we have API commands to upload new data, the `old_stats` can come from Databrary directly.

```{r get-databrary-stats}
new_stats <- databraryapi::get_db_stats()
# old_stats <- read_csv("csv/institutionAuthCounts.csv")
new_stats$date <- lubridate::as_datetime(new_stats$date)
```


```{r data-from-googlesheets}
#key <- "1tvlIQzULrMtXo97aJu71ljdTmNXkwwpU9eOOasVer3g"
db <- gs_title('Databrary-analytics')
```

Now, let's load the data about the number of institutions, investigators and affiliates.

```{r load-inst-invest-from-googlesheets}
old_stats <- db %>%
  gs_read(ws = 'institutions-investigators')
```

We then update the old stats with new data if `params$update_stats` is TRUE.

```{r update-stats}
# initialize updated_stats
updated_stats <- old_stats
if (as.logical(params$update_stats)) {
  next_entry <- dim(updated_stats)[1] + 1
  updated_stats[next_entry,] = NA
  updated_stats <- updated_stats
  
  # fill with new data
  updated_stats$date[next_entry] <- new_stats$date
  updated_stats$institutions[next_entry] <- new_stats$institutions
  updated_stats$investigators[next_entry] <- new_stats$investigators
  updated_stats$affiliates[next_entry] <- new_stats$affiliates
}
```



```{r db-inst-user-plot}

# Create a tidy form for plotting both institutions and investigators and affiliates
updated_stats <- updated_stats %>%
  gather(., key = "type", value = "count", -date) %>%
  mutate(date = lubridate::as_date(date)) %>%
  select(date, count, type) %>%
  filter(type %in% c('institutions', 'investigators', 'affiliates')) %>%
  filter(!is.na(count))


# Plot
p <- updated_stats %>%
  ggplot(., aes(x = date, y = count, color = type, group = type)) +
  geom_point() + 
  geom_line(size = ln_size) +
  scale_colour_manual(values=c(color_purple, color_orange, color_teal)) +  
  ylab("Authorizations") +
  databrary_theme +
  scale_y_continuous(breaks = seq(0, round_any(max(updated_stats$count), 100, ceiling), 100), expand = c(0,0)) +
  coord_cartesian(ylim = c(0, round_any(max(updated_stats$count), 100, ceiling)))
  
ggdraw(p) + 
  draw_label("Investigators", colour = color_teal, .8, .9) +
  draw_label("Institutions", colour = color_orange, .9, .6)+
  draw_label("Affiliates", colour = color_purple, .9, .3)
```

##  New investigators

```{r}
new_people <- databraryapi::get_db_stats(type = "people")
new_people %>%
  select(., sortname, prename, affiliation) %>%
  knitr::kable()
```

## New institutions

```{r}
new_institutions <- databraryapi::get_db_stats(type = "institutions")
new_institutions %>%
  select(., sortname, url) %>%
  knitr::kable()
```

Next, we update the Google Sheet if `params$update_gs` is TRUE.
In the current context, `params$update_gs` == `r params$update_gs`.

```{r update-inst-inv-gs}
if (as.logical(params$update_gs)) {
  db <- db %>%
    gs_add_row(ws = 'institutions-investigators', input = new_stats[,c(1, 4, 2, 3)])
  message("'update_gs' parameter is 'TRUE', so Google Sheet data will be updated.")
} else {
  message("'update_gs' parameter is 'FALSE', so Google Sheet data unmodified.")
}
```

# Volumes

The volumes data can also be rewritten back to Databrary at some future date.

```{r}
old_vols <- read_csv("csv/db-volumes-monthly.csv")

# Update
updated_vols <- old_vols
next_entry <- dim(updated_vols)[1] + 1
updated_vols[next_entry,] = NA

updated_vols$date[next_entry] <- new_stats$date
updated_vols$shared_volumes[next_entry] <- new_stats$datasets_shared
updated_vols$unshared_volumes[next_entry] <- 
  new_stats$datasets_total - new_stats$datasets_shared
```

```{r db-vols-plot}
updated_vols <- updated_vols %>%
  gather(., key = "type", value = "count", -date)

# Plot
vols_plot <- updated_vols %>%
  ggplot(., aes(x = date, y = count, color = type, group = type)) +
  geom_point() + 
  geom_line(size=ln_size) +
  scale_colour_manual(values=c(color_orange, color_teal)) +  
  ylab("Volumes") +
  databrary_theme +
  scale_y_continuous(breaks = seq(0, round_any(max(updated_vols$count), 100, ceiling), 100), expand = c(0,0)) +
  coord_cartesian(ylim = c(0, round_any(max(updated_vols$count), 100, ceiling)))
  
ggdraw(vols_plot) + 
  draw_label("Unshared", colour = color_teal, .86, .88) +
  draw_label("Shared", colour = color_orange, .84, .75)
```
Next, we update the Google Sheet if `params$update_gs` is TRUE.
In the current context, `params$update_gs` == `r params$update_gs`.

#```{r update-shared-vols-gs}
if (as.logical(params$update_gs)) {
  db <- db %>%
    gs_add_row(ws = 'volumes-shared-unshared', input = new_data[,c(1, 2, 3])
  message("'update_gs' parameter is 'TRUE', so Google Sheet data will be updated.")
} else {
  message("'update_gs' parameter is 'FALSE', so Google Sheet data unmodified.")
}
```


## New volumes

```{r}
new_volumes <- databraryapi::get_db_stats(type = "datasets")
new_volumes %>%
  select(., name, creation, owners) %>%
  knitr::kable()
```


# Citation counts

```{r get-new-citations}
# Get citation counts from Google Scholar
get_citation_stats <- function(project = 'databrary') {
  if (project %in% c('databrary', 'Databrary')) {
    url <- 'https://scholar.google.com/scholar?hl=en&as_sdt=1%2C39&as_vis=1&q=%22databrary%22&btnG='
  } else if (project %in% c('datavyu', 'Datavyu')) {
    url <- 'https://scholar.google.com/scholar?hl=en&as_sdt=1%2C39&as_vis=1&q=%22datavyu%22&btnG='
  }
  
  r <- httr::GET(url = url)
  if (httr::status_code(r) == 200) {
    content <- httr::content(r, 'text')
  } else {
    message(paste0('Download Failed, HTTP status ', httr::status_code(r)))
  }
  
  n_results <- stringr::str_match(content, pattern = "About ([0-9]+)")[2]
  if (is.null(n_results)) {
    message(paste0('Unable to parse results from search.'))
    return(NULL)
  } else {
    return(as.numeric(n_results))
  }
}

databrary_cites <- get_citation_stats('databrary')
datavyu_cites <- get_citation_stats('datavyu')

old_citations <- citations <- read_csv("csv/citations-monthly.csv")
next_value <- dim(old_citations)[1] + 1
citations <- old_citations
citations[next_value,] <- NA

citations$date[next_value] <- Sys.Date()
citations$databrary_citations[next_value] <- databrary_cites
citations$datavyu_citations[next_value] <- datavyu_cites
```

```{r db-dv-citations-plot}
citations <- citations %>%
  gather(., key = "type", value = "count", -date)

# Plot
citations_plot <- 
  citations %>%
  ggplot(., aes(x = date, y = count, color = type, group = type)) +
  geom_point() + 
  geom_line(size = ln_size) +
  scale_colour_manual(values=c(color_orange, color_teal)) +
  ylab("Citations") +
  databrary_theme +
 scale_y_continuous(breaks = seq(0, round_any(max(citations$count), 100, ceiling), 100), expand = c(0,0)) +
  coord_cartesian(ylim = c(0, round_any(max(citations$count), 100, ceiling)))
  
  
ggdraw(citations_plot) + 
  draw_label("Datavyu", colour = color_teal, .9, .6) +
  draw_label("Databrary", colour = color_orange, .7, .85)
```
#```{r update-citations-gs}

## This is WRONG. Fix

if (as.logical(params$update_gs)) {
  db <- db %>%
    gs_add_row(ws = 'citations-monthly', input = new_stats[,c(1)], input(,c(2))= databrary_cites[(1)], datavyu_cites[(1)])
  message("'update_gs' parameter is 'TRUE', so Google Sheet data will be updated.")
} else {
  message("'update_gs' parameter is 'FALSE', so Google Sheet data unmodified.")
}



# Data about volumes with videos

```{r}
# List files with metadata
csv_files <- list.files(path = "csv", pattern = "vol_", full.names = TRUE)

# Extract vector of volume numbers, determine the maximum
vol_nums <- stringr::str_match(csv_files, pattern = "_([0-9]+)\\.")
vol_ids <- as.numeric(vol_nums[,2])
last_vol <- max(vol_ids)
vols_to_test <- params$vols_to_test

# Create function to write new data files for each volume
write_vid_csv <- function(vol.id = 1) {
  message(paste0("Getting data for volume ", vol.id))
  vid_dat <- get_video_stats(vol.id)
  # This .Rmd file is already in working/
  if (!is.null(vid_dat)) {
    write.csv(vid_dat, file = paste0("csv/vol_", vol.id, ".csv"),
              row.names = FALSE)
  }
} 
```

```{r query-for-video-data, include=FALSE}
lapply(last_vol:(last_vol + vols_to_test), write_vid_csv)
```

```{r}
vol_files <- list.files("csv", pattern = "vol_[0-9]+", full.names = TRUE)

# Import the individual csv files
video_data <- lapply(vol_files, read_csv)
video_stats <- Reduce(function(x,y) merge(x, y, all = TRUE), video_data)
```

The median number of videos per volume is `r median(video_stats$n_videos)` with a range of [`r min(video_stats$n_videos)`, `r max(video_stats$n_videos)`].

```{r}
vols <- video_stats$vol_id
vol_info <- lapply(vols, list_volume_metadata)
vols_data <- Reduce(function(x,y) merge(x, y, all = TRUE), vol_info)
vols_joined <- dplyr::left_join(vols_data, video_stats, by = c("vol_id" = "vol_id"))
```

There are `r dim(vols_data[vols_data$doi != "NA",])[1]` volumes with DOIs (shared) that have sessions and at least one video as of today (`r Sys.time()`).

## Number of videos in (shared) volumes

```{r n-vids-shared-vols}
vols_joined %>%
  filter(!is.na(doi)) %>%
  ggplot(.) +
  aes(x=n_videos)+
  geom_histogram()
```

## Number of sessions in (shared) volumes

```{r n-sessions-shared-vols}
vols_joined %>%
  filter(!is.na(doi)) %>%
  ggplot(.) +
  aes(x=n_sessions)+
  geom_histogram()
```

## Total video hours in (shared) volumes

```{r tot-hrs-shared-vols}
vols_joined %>%
  filter(!is.na(doi)) %>%
  ggplot(.) +
  aes(x=tot_hrs)+
  geom_histogram()
```
